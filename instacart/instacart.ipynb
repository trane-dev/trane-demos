{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_instacart_data\n",
    "\n",
    "dataframes, metadata = load_instacart_data(nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Generated 54 total problems\n",
      "--------------------------------------------------\n",
      "Classification problems: 9\n",
      "Regression problems: 45\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from trane import ProblemGenerator\n",
    "\n",
    "problem_generator = ProblemGenerator(\n",
    "    metadata=metadata,\n",
    "    window_size=\"2w\",\n",
    "    target_table=\"orders\",\n",
    ")\n",
    "problems = problem_generator.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trane.parsing.denormalize import (\n",
    "    denormalize,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, single_metadata = denormalize(\n",
    "    metadata=metadata,\n",
    "    target_table=\"orders\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'order_id': Integer, 'order_time': Datetime, 'user_id': Integer})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_metadata.ml_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "ID: 1 Problem: For each order_id predict if there exists a record in the next 2 weeks.\n",
       "Reasoning: This problem can help determine if customers are likely to make another purchase within a specific time frame and can inform marketing strategies to target these customers.\n",
       "\n",
       "ID: 13 Problem: For each order_id predict the number of records in the next 2 weeks.\n",
       "Reasoning: This problem can provide insights into the frequency of customer purchases and can help identify customers who make multiple purchases, indicating higher engagement and potential loyalty.\n",
       "\n",
       "ID: 28 Problem: For each user_id predict the minimum user_id in all related records in the next 2 weeks.\n",
       "Reasoning: This problem can identify the earliest user_id associated with a customer's purchase history and can be used to understand the customer's initial interaction with the product or service.\n",
       "\n",
       "ID: 30 Problem: For each user_id predict the minimum user_id in all related records with user_id less than a float value in the next 2 weeks.\n",
       "Reasoning: This problem can help identify the earliest user_id associated with a specific segment of customers, such as those with a lower user_id, allowing for targeted analysis of different customer groups.\n",
       "\n",
       "ID: 41 Problem: Predict the average user_id in all related records with user_id greater than a float value in the next 2 weeks.\n",
       "Reasoning: This problem can provide insights into the average user_id of customers who have higher user_ids, potentially indicating patterns or preferences among specific customer segments."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 13, 28, 30, 41]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[For each <order_id> predict if there exists a record in next 2w days,\n",
       " For each <order_id> predict the number of records in next 2w days,\n",
       " For each <user_id> predict the minimum <user_id> in all related records in next 2w days,\n",
       " For each <user_id> predict the minimum <user_id> in all related records with <user_id> less than <float> in next 2w days,\n",
       " Predict the average <user_id> in all related records with <user_id> greater than <float> in next 2w days]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trane.llm import analyze\n",
    "\n",
    "instructions = \"determine 5 most relevant problems about consumers future product preferences\"\n",
    "context = \"a relational set of files describing customers' orders over time\"\n",
    "\n",
    "relevant_problems = analyze(\n",
    "    problems=problems,\n",
    "    instructions=instructions,\n",
    "    context=context,\n",
    "    model=\"gpt-3.5-turbo-16k\"\n",
    ")\n",
    "relevant_problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = problems[273].execute(df, num_examples_per_instance=-1)\n",
    "problems[273]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "Using Featuretools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft\n",
    "\n",
    "es = ft.EntitySet(name)\n",
    "\n",
    "es.add_dataframe(\n",
    "    dataframe=df.reset_index(),\n",
    "    dataframe_name=\"order_products\",\n",
    "    time_index=\"orders.order_date\",\n",
    "    index=\"__id__\",\n",
    ")\n",
    "\n",
    "es.normalize_dataframe(\n",
    "    base_dataframe_name=\"order_products\",\n",
    "    new_dataframe_name=\"products\",\n",
    "    index=\"product_id\",\n",
    "    additional_columns=[\"products.aisle_id\", \"products.aisles.aisle\", \"products.department_id\", \"products.departments.department\", \"products.product_name\"],\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es.normalize_dataframe(\n",
    "    base_dataframe_name=\"order_products\",\n",
    "    new_dataframe_name=\"orders\",\n",
    "    index=\"order_id\",\n",
    "    additional_columns=[\"orders.user_id\", \"orders.eval_set\", \"orders.order_number\", \"orders.order_dow\", \"orders.order_hour_of_day\", \"orders.days_since_prior_order\"],\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es.normalize_dataframe(\n",
    "    base_dataframe_name=\"products\",\n",
    "    new_dataframe_name=\"aisles\",\n",
    "    index=\"products.aisle_id\",\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es.normalize_dataframe(\n",
    "    base_dataframe_name=\"products\",\n",
    "    new_dataframe_name=\"departments\",\n",
    "    index=\"products.department_id\",\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es.normalize_dataframe(\n",
    "    base_dataframe_name=\"orders\",\n",
    "    new_dataframe_name=\"orders.user_id\",\n",
    "    index=\"orders.user_id\",\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm, fd = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_dataframe_name=entity_col,\n",
    "    cutoff_time=ex,\n",
    "    cutoff_time_in_index=True,\n",
    "    include_cutoff_time=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "fm.reset_index(drop=True, inplace=True)\n",
    "y = fm.ww.pop('_execute_operations_on_df')\n",
    "X = fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train/Test split by time cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cutoff = pd.to_datetime(\"2023-09-01\")\n",
    "X_train, y_train = X[ex[\"time\"] <= train_cutoff], y[ex[\"time\"] <= train_cutoff]\n",
    "X_test, y_test = X[ex[\"time\"] > train_cutoff], y[ex[\"time\"] > train_cutoff]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run inference on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    ax = sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_confusion_matrix(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "print(f\"AUC: {round(roc_auc_score(y_test, y_hat), 2)}\")\n",
    "print(f\"F1 Score: {round(f1_score(y_test, y_hat), 2)}\")\n",
    "print(f\"Accuracy: {round(accuracy_score(y_test, y_hat), 2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
