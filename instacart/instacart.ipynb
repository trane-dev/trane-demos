{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trane.parsing import denormalize, denormalize2\n",
    "import pandas as pd\n",
    "from util import load_data\n",
    "\n",
    "dataframes, relationships = load_data()\n",
    "\n",
    "df = denormalize(\n",
    "    dataframes,\n",
    "    relationships,\n",
    "    \"order_products\"\n",
    ")\n",
    "df = df.dropna()\n",
    "\n",
    "df[\"orders.user_id\"] = df[\"orders.user_id\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trane import CutoffStrategy\n",
    "from trane.typing.column_schema import ColumnSchema\n",
    "from trane.typing.logical_types import (\n",
    "    Categorical,\n",
    "    Datetime,\n",
    "    Double,\n",
    "    Integer,\n",
    ")\n",
    "\n",
    "entity_col = \"orders.user_id\"\n",
    "time_col = \"orders.order_date\"\n",
    "\n",
    "def get_meta(df, entity_col):\n",
    "    meta = {}\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"int\":\n",
    "            meta[col] = ColumnSchema(\n",
    "                Integer,\n",
    "                semantic_tags=({\"numeric\"} if col != entity_col else {\"numeric\", \"index\"})\n",
    "            )\n",
    "        if df[col].dtype == \"float\":\n",
    "            meta[col] = ColumnSchema(\n",
    "                Double,\n",
    "                semantic_tags=({\"numeric\"} if col != entity_col else {\"numeric\", \"index\"})\n",
    "            )\n",
    "        if df[col].dtype == \"object\":\n",
    "            meta[col] = ColumnSchema(\n",
    "                Categorical,\n",
    "                semantic_tags=({\"category\"} if col != entity_col else {\"category\", \"index\"})\n",
    "            )\n",
    "        if df[col].dtype == \"datetime64[ns]\":\n",
    "            meta[col] = ColumnSchema(\n",
    "                Datetime,\n",
    "                semantic_tags=({} if col != entity_col else {\"index\"})\n",
    "            )\n",
    "    return meta\n",
    "meta = get_meta(df, entity_col)\n",
    "\n",
    "cutoff_strategy = CutoffStrategy(\n",
    "    entity_col=entity_col,\n",
    "    window_size=\"2w\",\n",
    "    minimum_data=\"2023-01-01\",\n",
    "    maximum_data=\"2023-10-01\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate prediction problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94eae67855624442980247b767501b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trane import PredictionProblemGenerator\n",
    "problem_generator = PredictionProblemGenerator(\n",
    "    df=df,\n",
    "    table_meta=meta,\n",
    "    entity_col=entity_col,\n",
    "    cutoff_strategy=cutoff_strategy,\n",
    "    time_col=time_col,\n",
    ")\n",
    "problems = problem_generator.generate(df, generate_thresholds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each <orders.user_id> predict the number of records with <orders.eval_set> equal to prior in next 2w days\n",
      "For each <orders.user_id> predict the total <reordered> in all related records with <product_id> greater than 40606 in next 2w days\n",
      "For each <orders.user_id> predict the maximum <reordered> in all related records with <order_id> less than 1282983 in next 2w days\n",
      "For each <orders.user_id> predict the total <products.aisle_id> in all related records with <products.department_id> greater than 4 in next 2w days\n",
      "For each <orders.user_id> predict if there exists a record with with <products.aisles.aisle> equal to fresh vegetables in next 2w days\n",
      "For each <orders.user_id> predict the maximum <order_id> in all related records with <products.aisles.aisle> equal to fresh fruits in next 2w days\n",
      "For each <orders.user_id> predict the minimum <reordered> in all related records with <reordered> less than 1 in next 2w days\n",
      "For each <orders.user_id> predict the maximum <orders.days_since_prior_order> in all related records with <reordered> greater than 1 in next 2w days\n",
      "For each <orders.user_id> predict the minimum <orders.order_dow> in all related records with <reordered> greater than 1 in next 2w days\n",
      "For each <orders.user_id> predict the minimum <order_id> in all related records with <orders.eval_set> not equal to prior in next 2w days\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for problem in np.array(problems)[np.random.choice(range(len(problems)), 10)]:\n",
    "    print(problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a relevant problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"generated_problems.txt\", \"w\") as text_file:\n",
    "    for idx, p in enumerate(problems):\n",
    "        print(idx, p, file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 00:41 | Remaining: 00:00 | Progress: 100%|██████████| orders.user_id: 10000/10000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "For each <orders.user_id> predict if there exists a record with with <products.product_name> equal to Bag of Organic Bananas in next 2w days"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = problems[3781].execute(df, num_examples_per_instance=-1)\n",
    "problems[3781]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/trane2/lib/python3.10/site-packages/featuretools/entityset/entityset.py:1910: UserWarning: index id not found in dataframe, creating new integer column\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.1.0 (20230707.0739)\n",
       " -->\n",
       "<!-- Title: instacart Pages: 1 -->\n",
       "<svg width=\"710pt\" height=\"428pt\"\n",
       " viewBox=\"0.00 0.00 710.00 428.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 424)\">\n",
       "<title>instacart</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-424 706,-424 706,4 -4,4\"/>\n",
       "<!-- order_products -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>order_products</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"130.12,-271.5 130.12,-419.5 371.88,-419.5 371.88,-271.5 130.12,-271.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"251\" y=\"-402.2\" font-family=\"Times,serif\" font-size=\"14.00\">order_products (1446475 rows)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"130.12,-395 371.88,-395\"/>\n",
       "<text text-anchor=\"start\" x=\"138.12\" y=\"-377.7\" font-family=\"Times,serif\" font-size=\"14.00\">id : Integer; index</text>\n",
       "<text text-anchor=\"start\" x=\"138.12\" y=\"-361.2\" font-family=\"Times,serif\" font-size=\"14.00\">index : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"138.12\" y=\"-344.7\" font-family=\"Times,serif\" font-size=\"14.00\">order_id : Integer; foreign_key</text>\n",
       "<text text-anchor=\"start\" x=\"138.12\" y=\"-328.2\" font-family=\"Times,serif\" font-size=\"14.00\">orders.order_date : Datetime; time_index</text>\n",
       "<text text-anchor=\"start\" x=\"138.12\" y=\"-311.7\" font-family=\"Times,serif\" font-size=\"14.00\">product_id : Integer; foreign_key</text>\n",
       "<text text-anchor=\"start\" x=\"138.12\" y=\"-295.2\" font-family=\"Times,serif\" font-size=\"14.00\">add_to_cart_order : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"138.12\" y=\"-278.7\" font-family=\"Times,serif\" font-size=\"14.00\">reordered : Integer</text>\n",
       "</g>\n",
       "<!-- orders -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>orders</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-86.5 0,-234.5 232,-234.5 232,-86.5 0,-86.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-217.2\" font-family=\"Times,serif\" font-size=\"14.00\">orders (145676 rows)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-210 232,-210\"/>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-192.7\" font-family=\"Times,serif\" font-size=\"14.00\">order_id : Integer; index</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-176.2\" font-family=\"Times,serif\" font-size=\"14.00\">orders.user_id : Integer; foreign_key</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-159.7\" font-family=\"Times,serif\" font-size=\"14.00\">orders.eval_set : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-143.2\" font-family=\"Times,serif\" font-size=\"14.00\">orders.order_number : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-126.7\" font-family=\"Times,serif\" font-size=\"14.00\">orders.order_dow : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-110.2\" font-family=\"Times,serif\" font-size=\"14.00\">orders.order_hour_of_day : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-93.7\" font-family=\"Times,serif\" font-size=\"14.00\">orders.days_since_prior_order : Double</text>\n",
       "</g>\n",
       "<!-- order_products&#45;&gt;orders -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>order_products&#45;&gt;orders</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M181.06,-271.59C181.06,-271.59 181.06,-245.3 181.06,-245.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"184.56,-245.3 181.06,-235.3 177.56,-245.3 184.56,-245.3\"/>\n",
       "<text text-anchor=\"middle\" x=\"158.19\" y=\"-245.14\" font-family=\"Times,serif\" font-size=\"14.00\">order_id</text>\n",
       "</g>\n",
       "<!-- products -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>products</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"250.12,-94.75 250.12,-226.25 521.88,-226.25 521.88,-94.75 250.12,-94.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"386\" y=\"-208.95\" font-family=\"Times,serif\" font-size=\"14.00\">products (34550 rows)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"250.12,-201.75 521.88,-201.75\"/>\n",
       "<text text-anchor=\"start\" x=\"258.12\" y=\"-184.45\" font-family=\"Times,serif\" font-size=\"14.00\">product_id : Integer; index</text>\n",
       "<text text-anchor=\"start\" x=\"258.12\" y=\"-167.95\" font-family=\"Times,serif\" font-size=\"14.00\">products.aisle_id : Integer; foreign_key</text>\n",
       "<text text-anchor=\"start\" x=\"258.12\" y=\"-151.45\" font-family=\"Times,serif\" font-size=\"14.00\">products.aisles.aisle : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"258.12\" y=\"-134.95\" font-family=\"Times,serif\" font-size=\"14.00\">products.department_id : Integer; foreign_key</text>\n",
       "<text text-anchor=\"start\" x=\"258.12\" y=\"-118.45\" font-family=\"Times,serif\" font-size=\"14.00\">products.departments.department : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"258.12\" y=\"-101.95\" font-family=\"Times,serif\" font-size=\"14.00\">products.product_name : Categorical</text>\n",
       "</g>\n",
       "<!-- order_products&#45;&gt;products -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>order_products&#45;&gt;products</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M311,-271.59C311,-271.59 311,-237.22 311,-237.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"314.5,-237.22 311,-227.22 307.5,-237.22 314.5,-237.22\"/>\n",
       "<text text-anchor=\"middle\" x=\"281.75\" y=\"-257.6\" font-family=\"Times,serif\" font-size=\"14.00\">product_id</text>\n",
       "</g>\n",
       "<!-- customers -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>customers</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"25.88,-0.5 25.88,-49.5 206.12,-49.5 206.12,-0.5 25.88,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-32.2\" font-family=\"Times,serif\" font-size=\"14.00\">customers (10000 rows)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"25.88,-25 206.12,-25\"/>\n",
       "<text text-anchor=\"start\" x=\"33.88\" y=\"-7.7\" font-family=\"Times,serif\" font-size=\"14.00\">orders.user_id : Integer; index</text>\n",
       "</g>\n",
       "<!-- orders&#45;&gt;customers -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>orders&#45;&gt;customers</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M116,-86.8C116,-86.8 116,-60.35 116,-60.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"119.5,-60.35 116,-50.35 112.5,-60.35 119.5,-60.35\"/>\n",
       "<text text-anchor=\"middle\" x=\"77.38\" y=\"-60.27\" font-family=\"Times,serif\" font-size=\"14.00\">orders.user_id</text>\n",
       "</g>\n",
       "<!-- aisles -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>aisles</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"256.38,-0.5 256.38,-49.5 451.62,-49.5 451.62,-0.5 256.38,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"354\" y=\"-32.2\" font-family=\"Times,serif\" font-size=\"14.00\">aisles (134 rows)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"256.38,-25 451.62,-25\"/>\n",
       "<text text-anchor=\"start\" x=\"264.38\" y=\"-7.7\" font-family=\"Times,serif\" font-size=\"14.00\">products.aisle_id : Integer; index</text>\n",
       "</g>\n",
       "<!-- products&#45;&gt;aisles -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>products&#45;&gt;aisles</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M354,-95.13C354,-95.13 354,-60.28 354,-60.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"357.5,-60.28 354,-50.28 350.5,-60.28 357.5,-60.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"307.88\" y=\"-80.9\" font-family=\"Times,serif\" font-size=\"14.00\">products.aisle_id</text>\n",
       "</g>\n",
       "<!-- departments -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>departments</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"470,-0.5 470,-49.5 702,-49.5 702,-0.5 470,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"586\" y=\"-32.2\" font-family=\"Times,serif\" font-size=\"14.00\">departments (21 rows)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"470,-25 702,-25\"/>\n",
       "<text text-anchor=\"start\" x=\"478\" y=\"-7.7\" font-family=\"Times,serif\" font-size=\"14.00\">products.department_id : Integer; index</text>\n",
       "</g>\n",
       "<!-- products&#45;&gt;departments -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>products&#45;&gt;departments</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M495.94,-95.13C495.94,-95.13 495.94,-60.28 495.94,-60.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"499.44,-60.28 495.94,-50.28 492.44,-60.28 499.44,-60.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"431.44\" y=\"-80.9\" font-family=\"Times,serif\" font-size=\"14.00\">products.department_id</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x284879870>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import featuretools as ft\n",
    "es = ft.EntitySet('instacart')\n",
    "\n",
    "es.add_dataframe(\n",
    "    dataframe=df.reset_index(),\n",
    "    dataframe_name='order_products',\n",
    "    time_index='orders.order_date',\n",
    "    index='id',\n",
    ")\n",
    "\n",
    "es.normalize_dataframe(\n",
    "    base_dataframe_name='order_products',\n",
    "    new_dataframe_name='orders',\n",
    "    index='order_id',\n",
    "    additional_columns=[col for col in df.columns if col.startswith('orders.') and col != \"orders.order_date\"],\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es.normalize_dataframe(\n",
    "    base_dataframe_name='orders',\n",
    "    new_dataframe_name='customers',\n",
    "    index='orders.user_id',\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es.normalize_dataframe(\n",
    "    base_dataframe_name='order_products',\n",
    "    new_dataframe_name='products',\n",
    "    index='product_id',\n",
    "    additional_columns=[col for col in df.columns if col.startswith('products')],\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es.normalize_dataframe(\n",
    "    base_dataframe_name='products',\n",
    "    new_dataframe_name='aisles',\n",
    "    index='products.aisle_id',\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es.normalize_dataframe(\n",
    "    base_dataframe_name='products',\n",
    "    new_dataframe_name='departments',\n",
    "    index='products.department_id',\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 170 features\n",
      "Elapsed: 03:37 | Progress: 100%|██████████\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>COUNT(orders)</th>\n",
       "      <th>MAX(orders.orders.days_since_prior_order)</th>\n",
       "      <th>MAX(orders.orders.order_dow)</th>\n",
       "      <th>MAX(orders.orders.order_hour_of_day)</th>\n",
       "      <th>MAX(orders.orders.order_number)</th>\n",
       "      <th>MEAN(orders.orders.days_since_prior_order)</th>\n",
       "      <th>MEAN(orders.orders.order_dow)</th>\n",
       "      <th>MEAN(orders.orders.order_hour_of_day)</th>\n",
       "      <th>MEAN(orders.orders.order_number)</th>\n",
       "      <th>MIN(orders.orders.days_since_prior_order)</th>\n",
       "      <th>...</th>\n",
       "      <th>SKEW(order_products.orders.orders.order_number)</th>\n",
       "      <th>STD(order_products.orders.orders.days_since_prior_order)</th>\n",
       "      <th>STD(order_products.orders.orders.order_dow)</th>\n",
       "      <th>STD(order_products.orders.orders.order_hour_of_day)</th>\n",
       "      <th>STD(order_products.orders.orders.order_number)</th>\n",
       "      <th>SUM(order_products.orders.orders.days_since_prior_order)</th>\n",
       "      <th>SUM(order_products.orders.orders.order_dow)</th>\n",
       "      <th>SUM(order_products.orders.orders.order_hour_of_day)</th>\n",
       "      <th>SUM(order_products.orders.orders.order_number)</th>\n",
       "      <th>_execute_operations_on_df</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orders.user_id</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>2023-02-12</th>\n",
       "      <td>9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>10.555556</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-13</th>\n",
       "      <td>9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>10.555556</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.853951</td>\n",
       "      <td>1.278275</td>\n",
       "      <td>2.572479</td>\n",
       "      <td>1.533930</td>\n",
       "      <td>429.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-27</th>\n",
       "      <td>9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>10.555556</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460805</td>\n",
       "      <td>10.890295</td>\n",
       "      <td>1.391388</td>\n",
       "      <td>3.463035</td>\n",
       "      <td>2.142693</td>\n",
       "      <td>574.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-10</th>\n",
       "      <td>9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>10.555556</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454978</td>\n",
       "      <td>10.051297</td>\n",
       "      <td>1.268228</td>\n",
       "      <td>3.734464</td>\n",
       "      <td>2.394672</td>\n",
       "      <td>664.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2023-03-12</th>\n",
       "      <td>13</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.230769</td>\n",
       "      <td>2.153846</td>\n",
       "      <td>10.538462</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           COUNT(orders)  \\\n",
       "orders.user_id time                        \n",
       "1              2023-02-12              9   \n",
       "               2023-08-13              9   \n",
       "               2023-08-27              9   \n",
       "               2023-09-10              9   \n",
       "2              2023-03-12             13   \n",
       "\n",
       "                           MAX(orders.orders.days_since_prior_order)  \\\n",
       "orders.user_id time                                                    \n",
       "1              2023-02-12                                       30.0   \n",
       "               2023-08-13                                       30.0   \n",
       "               2023-08-27                                       30.0   \n",
       "               2023-09-10                                       30.0   \n",
       "2              2023-03-12                                       30.0   \n",
       "\n",
       "                           MAX(orders.orders.order_dow)  \\\n",
       "orders.user_id time                                       \n",
       "1              2023-02-12                           4.0   \n",
       "               2023-08-13                           4.0   \n",
       "               2023-08-27                           4.0   \n",
       "               2023-09-10                           4.0   \n",
       "2              2023-03-12                           5.0   \n",
       "\n",
       "                           MAX(orders.orders.order_hour_of_day)  \\\n",
       "orders.user_id time                                               \n",
       "1              2023-02-12                                  16.0   \n",
       "               2023-08-13                                  16.0   \n",
       "               2023-08-27                                  16.0   \n",
       "               2023-09-10                                  16.0   \n",
       "2              2023-03-12                                  15.0   \n",
       "\n",
       "                           MAX(orders.orders.order_number)  \\\n",
       "orders.user_id time                                          \n",
       "1              2023-02-12                             10.0   \n",
       "               2023-08-13                             10.0   \n",
       "               2023-08-27                             10.0   \n",
       "               2023-09-10                             10.0   \n",
       "2              2023-03-12                             14.0   \n",
       "\n",
       "                           MEAN(orders.orders.days_since_prior_order)  \\\n",
       "orders.user_id time                                                     \n",
       "1              2023-02-12                                   19.555556   \n",
       "               2023-08-13                                   19.555556   \n",
       "               2023-08-27                                   19.555556   \n",
       "               2023-09-10                                   19.555556   \n",
       "2              2023-03-12                                   15.230769   \n",
       "\n",
       "                           MEAN(orders.orders.order_dow)  \\\n",
       "orders.user_id time                                        \n",
       "1              2023-02-12                       2.555556   \n",
       "               2023-08-13                       2.555556   \n",
       "               2023-08-27                       2.555556   \n",
       "               2023-09-10                       2.555556   \n",
       "2              2023-03-12                       2.153846   \n",
       "\n",
       "                           MEAN(orders.orders.order_hour_of_day)  \\\n",
       "orders.user_id time                                                \n",
       "1              2023-02-12                              10.555556   \n",
       "               2023-08-13                              10.555556   \n",
       "               2023-08-27                              10.555556   \n",
       "               2023-09-10                              10.555556   \n",
       "2              2023-03-12                              10.538462   \n",
       "\n",
       "                           MEAN(orders.orders.order_number)  \\\n",
       "orders.user_id time                                           \n",
       "1              2023-02-12                               6.0   \n",
       "               2023-08-13                               6.0   \n",
       "               2023-08-27                               6.0   \n",
       "               2023-09-10                               6.0   \n",
       "2              2023-03-12                               8.0   \n",
       "\n",
       "                           MIN(orders.orders.days_since_prior_order)  ...  \\\n",
       "orders.user_id time                                                   ...   \n",
       "1              2023-02-12                                        0.0  ...   \n",
       "               2023-08-13                                        0.0  ...   \n",
       "               2023-08-27                                        0.0  ...   \n",
       "               2023-09-10                                        0.0  ...   \n",
       "2              2023-03-12                                        3.0  ...   \n",
       "\n",
       "                           SKEW(order_products.orders.orders.order_number)  \\\n",
       "orders.user_id time                                                          \n",
       "1              2023-02-12                                              NaN   \n",
       "               2023-08-13                                         0.000000   \n",
       "               2023-08-27                                         0.460805   \n",
       "               2023-09-10                                         0.454978   \n",
       "2              2023-03-12                                              NaN   \n",
       "\n",
       "                           STD(order_products.orders.orders.days_since_prior_order)  \\\n",
       "orders.user_id time                                                                   \n",
       "1              2023-02-12                                                NaN          \n",
       "               2023-08-13                                           3.853951          \n",
       "               2023-08-27                                          10.890295          \n",
       "               2023-09-10                                          10.051297          \n",
       "2              2023-03-12                                                NaN          \n",
       "\n",
       "                           STD(order_products.orders.orders.order_dow)  \\\n",
       "orders.user_id time                                                      \n",
       "1              2023-02-12                                          NaN   \n",
       "               2023-08-13                                     1.278275   \n",
       "               2023-08-27                                     1.391388   \n",
       "               2023-09-10                                     1.268228   \n",
       "2              2023-03-12                                          NaN   \n",
       "\n",
       "                          STD(order_products.orders.orders.order_hour_of_day)  \\\n",
       "orders.user_id time                                                             \n",
       "1              2023-02-12                                                NaN    \n",
       "               2023-08-13                                           2.572479    \n",
       "               2023-08-27                                           3.463035    \n",
       "               2023-09-10                                           3.734464    \n",
       "2              2023-03-12                                                NaN    \n",
       "\n",
       "                           STD(order_products.orders.orders.order_number)  \\\n",
       "orders.user_id time                                                         \n",
       "1              2023-02-12                                             NaN   \n",
       "               2023-08-13                                        1.533930   \n",
       "               2023-08-27                                        2.142693   \n",
       "               2023-09-10                                        2.394672   \n",
       "2              2023-03-12                                             NaN   \n",
       "\n",
       "                           SUM(order_products.orders.orders.days_since_prior_order)  \\\n",
       "orders.user_id time                                                                   \n",
       "1              2023-02-12                                                0.0          \n",
       "               2023-08-13                                              429.0          \n",
       "               2023-08-27                                              574.0          \n",
       "               2023-09-10                                              664.0          \n",
       "2              2023-03-12                                                0.0          \n",
       "\n",
       "                           SUM(order_products.orders.orders.order_dow)  \\\n",
       "orders.user_id time                                                      \n",
       "1              2023-02-12                                          0.0   \n",
       "               2023-08-13                                         52.0   \n",
       "               2023-08-27                                         78.0   \n",
       "               2023-09-10                                         96.0   \n",
       "2              2023-03-12                                          0.0   \n",
       "\n",
       "                           SUM(order_products.orders.orders.order_hour_of_day)  \\\n",
       "orders.user_id time                                                              \n",
       "1              2023-02-12                                                0.0     \n",
       "               2023-08-13                                              225.0     \n",
       "               2023-08-27                                              356.0     \n",
       "               2023-09-10                                              398.0     \n",
       "2              2023-03-12                                                0.0     \n",
       "\n",
       "                           SUM(order_products.orders.orders.order_number)  \\\n",
       "orders.user_id time                                                         \n",
       "1              2023-02-12                                             0.0   \n",
       "               2023-08-13                                            90.0   \n",
       "               2023-08-27                                           164.0   \n",
       "               2023-09-10                                           176.0   \n",
       "2              2023-03-12                                             0.0   \n",
       "\n",
       "                           _execute_operations_on_df  \n",
       "orders.user_id time                                   \n",
       "1              2023-02-12                       True  \n",
       "               2023-08-13                      False  \n",
       "               2023-08-27                       True  \n",
       "               2023-09-10                      False  \n",
       "2              2023-03-12                      False  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm, fd = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_dataframe_name='customers',\n",
    "    cutoff_time=ex,\n",
    "    cutoff_time_in_index=True,\n",
    "    include_cutoff_time=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "fm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.reset_index(drop=True, inplace=True)\n",
    "y = fm.ww.pop('_execute_operations_on_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3dcb59855e4b0db54ddd9b9c5e4481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(learning_rate=0.01, max_depth=3, n_estimators=10, num_leaves=2)\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49589\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49589\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49589\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28876\n",
      "[LightGBM] [Info] Number of data points in the train set: 58314, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149621 -> initscore=-1.737577\n",
      "[LightGBM] [Info] Start training from score -1.737577\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28822\n",
      "[LightGBM] [Info] Number of positive: 8724, number of negative: 49589\n",
      "[LightGBM] [Info] Number of data points in the train set: 58314, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149621 -> initscore=-1.737577\n",
      "[LightGBM] [Info] Start training from score -1.737577\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49588\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28888\n",
      "[LightGBM] [Info] Number of data points in the train set: 58314, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149621 -> initscore=-1.737577\n",
      "[LightGBM] [Info] Start training from score -1.737577\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28878\n",
      "[LightGBM] [Info] Number of data points in the train set: 58313, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149606 -> initscore=-1.737691\n",
      "[LightGBM] [Info] Start training from score -1.737691\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28855\n",
      "[LightGBM] [Info] Number of data points in the train set: 58313, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149624 -> initscore=-1.737556\n",
      "[LightGBM] [Info] Start training from score -1.737556\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=10, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "DecisionTreeClassifier(max_depth=3, min_samples_split=0.01)\n",
      "SGDClassifier()\n",
      "RandomForestClassifier(max_depth=3, min_samples_split=0.01, n_estimators=10)\n",
      "LGBMClassifier(learning_rate=0.7496000919050138, max_depth=153,\n",
      "               n_estimators=385, num_leaves=94)\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49588\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49589\n",
      "[LightGBM] [Info] Number of positive: 8724, number of negative: 49589\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28855\n",
      "[LightGBM] [Info] Number of data points in the train set: 58313, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149624 -> initscore=-1.737556\n",
      "[LightGBM] [Info] Start training from score -1.737556\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28822\n",
      "[LightGBM] [Info] Number of data points in the train set: 58314, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149621 -> initscore=-1.737577\n",
      "[LightGBM] [Info] Start training from score -1.737577\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28878\n",
      "[LightGBM] [Info] Number of data points in the train set: 58313, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149606 -> initscore=-1.737691\n",
      "[LightGBM] [Info] Start training from score -1.737691\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49589\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49589\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28888\n",
      "[LightGBM] [Info] Number of data points in the train set: 58314, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149621 -> initscore=-1.737577\n",
      "[LightGBM] [Info] Start training from score -1.737577\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28876\n",
      "[LightGBM] [Info] Number of data points in the train set: 58314, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149621 -> initscore=-1.737577\n",
      "[LightGBM] [Info] Start training from score -1.737577\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "LGBMClassifier(learning_rate=0.6852056827034956, max_depth=19, n_estimators=13,\n",
      "               num_leaves=46)\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49589\n",
      "[LightGBM] [Info] Number of positive: 8724, number of negative: 49589\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49589\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49589\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28888\n",
      "[LightGBM] [Info] Number of data points in the train set: 58314, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149621 -> initscore=-1.737577\n",
      "[LightGBM] [Info] Start training from score -1.737577\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28878\n",
      "[LightGBM] [Info] Total Bins 28822\n",
      "[LightGBM] [Info] Number of data points in the train set: 58313, number of used features: 161\n",
      "[LightGBM] [Info] Number of data points in the train set: 58314, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149606 -> initscore=-1.737691\n",
      "[LightGBM] [Info] Start training from score -1.737691\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149621 -> initscore=-1.737577\n",
      "[LightGBM] [Info] Start training from score -1.737577\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28876\n",
      "[LightGBM] [Info] Number of data points in the train set: 58314, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149621 -> initscore=-1.737577\n",
      "[LightGBM] [Info] Start training from score -1.737577\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49588\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28855\n",
      "[LightGBM] [Info] Number of data points in the train set: 58313, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149624 -> initscore=-1.737556\n",
      "[LightGBM] [Info] Start training from score -1.737556\n",
      "LGBMClassifier(learning_rate=0.8469614394623889, max_depth=157,\n",
      "               n_estimators=408, num_leaves=93)\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49589\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49588\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49589\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49589\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28822\n",
      "[LightGBM] [Info] Number of data points in the train set: 58314, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149621 -> initscore=-1.737577\n",
      "[LightGBM] [Info] Start training from score -1.737577\n",
      "[LightGBM] [Info] Number of positive: 8724, number of negative: 49589\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28855\n",
      "[LightGBM] [Info] Number of data points in the train set: 58313, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149624 -> initscore=-1.737556\n",
      "[LightGBM] [Info] Start training from score -1.737556\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28876\n",
      "[LightGBM] [Info] Number of data points in the train set: 58314, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149621 -> initscore=-1.737577\n",
      "[LightGBM] [Info] Start training from score -1.737577\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28888\n",
      "[LightGBM] [Info] Number of data points in the train set: 58314, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149621 -> initscore=-1.737577\n",
      "[LightGBM] [Info] Start training from score -1.737577\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28878\n",
      "[LightGBM] [Info] Number of data points in the train set: 58313, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149606 -> initscore=-1.737691\n",
      "[LightGBM] [Info] Start training from score -1.737691\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "LGBMClassifier(learning_rate=0.6473321563764303, max_depth=149,\n",
      "               n_estimators=608, num_leaves=24)\n",
      "[LightGBM] [Info] Number of positive: 8724, number of negative: 49589\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49589\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49589\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.106241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28878\n",
      "[LightGBM] [Info] Number of data points in the train set: 58313, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149606 -> initscore=-1.737691\n",
      "[LightGBM] [Info] Start training from score -1.737691\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28888\n",
      "[LightGBM] [Info] Number of data points in the train set: 58314, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149621 -> initscore=-1.737577\n",
      "[LightGBM] [Info] Start training from score -1.737577\n",
      "[LightGBM] [Info] Total Bins 28876\n",
      "[LightGBM] [Info] Number of data points in the train set: 58314, number of used features: 161\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49588\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149621 -> initscore=-1.737577\n",
      "[LightGBM] [Info] Start training from score -1.737577\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28855\n",
      "[LightGBM] [Info] Number of data points in the train set: 58313, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149624 -> initscore=-1.737556\n",
      "[LightGBM] [Info] Start training from score -1.737556\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49589\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28822\n",
      "[LightGBM] [Info] Number of data points in the train set: 58314, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149621 -> initscore=-1.737577\n",
      "[LightGBM] [Info] Start training from score -1.737577\n",
      "LGBMClassifier(learning_rate=0.6775986855717634, max_depth=153,\n",
      "               n_estimators=568, num_leaves=23)\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49589\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49589\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49589\n",
      "[LightGBM] [Info] Number of positive: 8725, number of negative: 49588\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28888\n",
      "[LightGBM] [Info] Number of data points in the train set: 58314, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149621 -> initscore=-1.737577\n",
      "[LightGBM] [Info] Start training from score -1.737577\n",
      "[LightGBM] [Info] Number of positive: 8724, number of negative: 49589\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28822\n",
      "[LightGBM] [Info] Number of data points in the train set: 58314, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149621 -> initscore=-1.737577\n",
      "[LightGBM] [Info] Start training from score -1.737577\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28876\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Number of data points in the train set: 58314, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149621 -> initscore=-1.737577\n",
      "[LightGBM] [Info] Start training from score -1.737577\n",
      "[LightGBM] [Info] Total Bins 28855\n",
      "[LightGBM] [Info] Number of data points in the train set: 58313, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149624 -> initscore=-1.737556\n",
      "[LightGBM] [Info] Start training from score -1.737556\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28878\n",
      "[LightGBM] [Info] Number of data points in the train set: 58313, number of used features: 161\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149606 -> initscore=-1.737691\n",
      "[LightGBM] [Info] Start training from score -1.737691\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "\n",
    "models = {\n",
    "    'LGB': lgb.LGBMClassifier,\n",
    "    'XGB': xgb.XGBClassifier,\n",
    "    'DTC': DecisionTreeClassifier,\n",
    "    'SGDC': SGDClassifier,\n",
    "    'RF': RandomForestClassifier,\n",
    "}\n",
    "\n",
    "def scoring_function(model_name, hyperparameter_values):\n",
    "    model_class = models[model_name]\n",
    "    model_instance = model_class(**hyperparameter_values)\n",
    "    print(model_instance)\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    scores = cross_val_score(\n",
    "        estimator=model_instance,\n",
    "        X=fm,\n",
    "        y=y,\n",
    "        scoring=make_scorer(roc_auc_score),\n",
    "        cv=skf,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    return scores.mean()\n",
    "\n",
    "from btb.tuning import Tunable\n",
    "from btb.tuning import hyperparams as hp\n",
    "\n",
    "tunables = {\n",
    "    'LGB': Tunable({\n",
    "        'num_leaves': hp.IntHyperParam(min=2, max=100),\n",
    "        'max_depth': hp.IntHyperParam(min=3, max=200),\n",
    "        'learning_rate': hp.FloatHyperParam(min=0.01, max=1),\n",
    "        'n_estimators': hp.IntHyperParam(min=10, max=1000),\n",
    "    }),\n",
    "    'XGB': Tunable({\n",
    "        'max_depth': hp.IntHyperParam(min=3, max=200),\n",
    "        'learning_rate': hp.FloatHyperParam(min=0.01, max=1),\n",
    "        'n_estimators': hp.IntHyperParam(min=10, max=1000),\n",
    "    }),\n",
    "    'DTC': Tunable({\n",
    "        'max_depth': hp.IntHyperParam(min=3, max=200),\n",
    "        'min_samples_split': hp.FloatHyperParam(min=0.01, max=1)\n",
    "    }),\n",
    "    'SGDC': Tunable({\n",
    "        'max_iter': hp.IntHyperParam(min=1, max=5000, default=1000),\n",
    "        'tol': hp.FloatHyperParam(min=1e-3, max=1, default=1e-3),\n",
    "    }),\n",
    "    'RF': Tunable({\n",
    "        'n_estimators': hp.IntHyperParam(min=10, max=1000),\n",
    "        'max_depth': hp.IntHyperParam(min=3, max=200),\n",
    "        'min_samples_split': hp.FloatHyperParam(min=0.01, max=1),\n",
    "    }),\n",
    "}\n",
    "\n",
    "from btb import BTBSession\n",
    "\n",
    "session = BTBSession(\n",
    "    tunables=tunables,\n",
    "    scorer=scoring_function,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "best_proposal = session.run(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '402ebd3e75a65094b407b95a1234c4af',\n",
       " 'name': 'LGB',\n",
       " 'config': {'num_leaves': 93,\n",
       "  'max_depth': 157,\n",
       "  'learning_rate': 0.8469614394623889,\n",
       "  'n_estimators': 408},\n",
       " 'score': 0.5196958961426631}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trane",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
